{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7804a632-bfe4-4edc-8db2-86f1295a101b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hands-On Assignment 3\n",
    "\n",
    "In this assignment, you will learn the basics of data cleaning and munging (manipulation).\n",
    "Data is the heart and soul of a data scientist and machine learner.\n",
    "Therefore, it is important for you to get comfortable taking data from its natural, messy state\n",
    "to a state where it is ready for machine learning algorithms.\n",
    "\n",
    "Since data is at the core of all we do, we learn to love data and treat it well.\n",
    "However, not everyone is a data scientist, a computer scientist, or even a programmer.\n",
    "Others that you work with may carefully collect very important data,\n",
    "but handling and storing the data may not be their expertise.\n",
    "So whenever working with data prepared by others,\n",
    "we must always treat their data with care and remember that even data presented in suboptimal ways can be of the utmost importance.\n",
    "Also remember that even as we learn better data handling practices,\n",
    "there will still be those with data handling skill and methodologies that are leagues better than our own.\n",
    "(It's database people, they are usually the best data people. (Written by Eriq, a database person.))\n",
    "\n",
    "The objective of this assignment is for you to learn about:\n",
    " - Finding errors and inconsistencies in data.\n",
    " - Extracting key pieces of information from a data column.\n",
    " - Assigning types to data columns.\n",
    " - Understanding and finding outliers in your data.\n",
    " - Replacing missing pieces of data.\n",
    " - Encoding data.\n",
    " - Joining data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f0a8f0-45fa-4d24-82a2-8cc0b47b6be3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data: CIA World Factbook - 2022\n",
    "\n",
    "For this assignment, we will be using data from the [CIA World Factbook](https://www.cia.gov/the-world-factbook/).\n",
    "This is a collection of real data about different countries and regions in the world compiled every year by the CIA.\n",
    "Specifically, we will be using the world factbook data from [this repository](https://github.com/factbook/factbook.json/) from 2022.\n",
    "\n",
    "The data can be found in your assignment repository in the `cia_world_factbook_2022.json` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb74c7-3376-4e63-b767-6fc33a8d73a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's take a look at the data as we have done in previous assignments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf1776-364f-41d8-921f-16b6829751e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas\n",
    "\n",
    "# Our data comes in JSON, so first parse the JSON data.\n",
    "with open('cia_world_factbook_2022.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Now load the JSON data into a Pandas dataframe.\n",
    "world_data = pandas.DataFrame.from_dict(data, orient = 'index')\n",
    "\n",
    "# Sort the data by country name so it looks nice.\n",
    "world_data.sort_index(axis = 0, inplace = True)\n",
    "\n",
    "# Move the country name out of the index and into an actual column.\n",
    "world_data.insert(0, 'Country', world_data.index)\n",
    "world_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "world_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d76c082-a6e0-442e-9a4c-69d57585c26e",
   "metadata": {},
   "source": [
    "Let's also take a look at the column information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcfa2d-36cc-43c4-abf4-144acbd75303",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ccc5d-cb6a-49fe-bb4e-951a477ad1c7",
   "metadata": {},
   "source": [
    "Now the numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43ca10-2a65-4425-934e-4e7f15ec0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860d8dd-f3b1-4e6d-9e75-5509cf7f09be",
   "metadata": {},
   "source": [
    "Note that when we tried to get information about the numerical columns like in a previous assignment,\n",
    "we didn't get nearly as much information as we did before.\n",
    "If we look back to `world_data.info()`,\n",
    "we can see this is because Pandas doesn't actually know which of our columns are numbers\n",
    "(the dtype (\"data type\") for each column is just `object`).\n",
    "If we look at some of the values (like \"38,346,720 (2022 est.)\"),\n",
    "we can see why Pandas would be confused about how to treat that data.\n",
    "Pandas will always try and choose a data type that can be applied to every value in the column.\n",
    "So if a column has a million ints and one float, then the column type will be float\n",
    "(since all ints are floats, but not all floats are ints).\n",
    "\n",
    "Let's see if we can cleanup this data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a376608-f74f-46cb-b7a9-88a363e8facf",
   "metadata": {},
   "source": [
    "## Part 1: Exploring Columns\n",
    "\n",
    "The first thing to do with a new dataset is explore the columns.\n",
    " - What data is each column suppose to contain?\n",
    " - What data type should be used to represent each column?\n",
    " - Which columns may be useful?\n",
    "\n",
    "Not all columns in each dataset are going to be useful.\n",
    "We can start our work by eliminating columns that have a low chance of being needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3734d92b-a941-4d2f-a6be-f499df2e6b01",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 1.A</h3>\n",
    "\n",
    "Complete the following function that takes in a frame and drops the columns in the frame that have greater than `sparsity_threshold` percent of values empty.\n",
    "Assume any value that [Pandas.isna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isna.html) returns true for is \"empty\".\n",
    "Return the passed-in frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d64b11-9394-424f-8c08-923c80adc676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sparse_columns(frame, sparsity_threshold):\n",
    "    return NotImplemented\n",
    "\n",
    "print(\"Dropping any column with at least 50% empty values:\")\n",
    "drop_sparse_columns(world_data, 0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1eb97-4c77-44de-92f7-ded55bf04b68",
   "metadata": {},
   "source": [
    "Now that we have fewer columns to worry about,\n",
    "we can take a closer look at our data.\n",
    "\n",
    "It looks like this data was originally meant for people and not machines.\n",
    "There are several things that make it easier for people to read, but harder for us machine learning folks:\n",
    " - Commas in numeric values: '38,346,720' instead of '38346720'.\n",
    " - Units after numbers: '53.65 years', '37.3%'.\n",
    " - Notes about the data interweaved with the data itself: '37.6% (2017 est.)' instead of just '37.6%' (or better: '0.376').\n",
    "\n",
    "Externally displaying data with these traits can really help analysts and non-data scientists,\n",
    "but can really get in the way of our data analysis work.\n",
    "When possible, we want to store the data cleanly and translate it to a more human readable form (often called a *report*) for readers, analysts, managers, etc..\n",
    "This also makes it easier to transform our data in different ways\n",
    "(like using a dot instead of a comma as a decimal separator in some countries: '1,000' vs '1.000')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee054306-f918-4e20-a75c-65a45cfb2d04",
   "metadata": {},
   "source": [
    "In our data, it looks like many columns just contain a single main number with some potential context information around it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806b48e-0ecf-4da6-8a9a-11a7e361bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_data['Population'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbab49d-fee2-4aca-abb6-4db9dedc7a02",
   "metadata": {},
   "source": [
    "There are also more complex cases that contain multiple relevant numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e80687-2909-4b70-a1d9-55511d0dca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_data['Population'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afebb8f2-5acd-4fe2-a1c1-9ad0cedb0ce1",
   "metadata": {},
   "source": [
    "We will want to clean up these cells so that they contain just the core piece of information and not all that extra information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7dabdb-0bf7-460b-808d-229c5ffd8565",
   "metadata": {},
   "source": [
    "### An Aside on Regular Expressions\n",
    "\n",
    "[Regular expressions](https://en.wikipedia.org/wiki/Regular_expression) (also called \"regexp\" or \"regex\") are patterns that let you find matching text.\n",
    "Think of them like mathematical expressions for text (an equation can define a line (collection of points), and a regex can define a set of strings).\n",
    "Covering regular expressions is outside the scope of this course,\n",
    "and they are **not necessary for any of the assignments in this course**.\n",
    "However, they can be very useful in many tasks (especially in data science).\n",
    "And once you get comfortable using them, you start to see how they can be used in almost all of your everyday coding.\n",
    "\n",
    "<center><img src=\"xkcd-regular-expressions.png\"/></center>\n",
    "<center style='font-size: small'>Comic courtesy of <a href='https://xkcd.com/208'>xkcd</a></center>\n",
    "\n",
    "We encourage you to learn about regular expressions and become comfortable using them in your everyday coding.\n",
    "Here are some resources to help you:\n",
    " - [Text Tutorial](https://www.sitepoint.com/learn-regex/)\n",
    " - [Video Tutorial](https://www.youtube.com/watch?v=sa-TUpSx1JA)\n",
    " - [Cheat Sheet](https://cheatography.com/davechild/cheat-sheets/regular-expressions/)\n",
    " - [Regex Playground](https://regex101.com/) (Interactivley create, test, and visualize regular expressions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ee3fa-fb41-4a07-88bd-17ce05d63028",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 1.B</h3>\n",
    "\n",
    "Complete the following function that takes in a frame and a list of columns to ignore.\n",
    "For all columns that are not ignored,\n",
    "extract a number from the cell's text and replace the cell's contents with that correctly typed number (either a `float` or `int`).\n",
    "The number should be converted to an `int` if the text does not have a decimal point (and is not a percentage).\n",
    "If the cell contains no number, replace it with a `numpy.nan`.\n",
    "Convert percentages to normalized floats, e.g., `str('37.6% (2017 est.)')` turns into `float(0.376)`.\n",
    "Return the passed-in frame.\n",
    "\n",
    "For cells with ambiguous data/numbers,\n",
    "it is your job to do your best to honor what that data's author likely intended.\n",
    "\n",
    "**Warning:\n",
    "This is a hard task with no exact answer (as with most tasks in machine learning).\n",
    "Look through the data to find as many edge cases as you can, turn those into test cases, and see how many you can solve.\n",
    "Start with a simple solution and work up from there.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678253b-04fd-4a51-823a-9d15a1535605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numbers(frame, ignore_columns = []):\n",
    "    return NotImplemented\n",
    "\n",
    "print(\"Cleaning up the numeric values:\")\n",
    "extract_numbers(world_data, ['Country', 'Export commodities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f294f25-7719-4880-86f7-54ea178a40b6",
   "metadata": {},
   "source": [
    "As a consequence of what we just did, we also standardized all the NaN values in those columns.\n",
    "Before we could see empty values represented in several different ways:\n",
    " - 'NaN'\n",
    " - 'NA'\n",
    " - 'total: NA'\n",
    " - '' (empty)\n",
    "\n",
    "Now, since any cell that didn't contain a number was replaced with `numpy.nan`,\n",
    "all numeric cells with missing/empty values are consistent.\n",
    "\n",
    "Now that we have cleaned up our numeric columns,\n",
    "let's officially tell Pandas the data types for our columns.\n",
    "Because even though most of our columns now only contains numbers (and `numpy.nan`),\n",
    "Pandas still needs to be told what data type each column uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63873dc-4446-47ca-bc2c-530804b40856",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359484d6-fa7b-4898-9e2e-f9500c1e89ca",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 1.C</h3>\n",
    "\n",
    "Complete the following function that takes in a frame and assigns the closest matching type to each column.\n",
    "You can choose from the following three types: `int`, `float`, and `str`.\n",
    "(Note that columns containing only integers should have the `int` type, not the `float` type.)\n",
    "Ignore any `numpy.nan` values when making decisions.\n",
    "Return the passed-in frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287abef2-3009-4e7b-b1f7-7c4300a59e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_types(frame):\n",
    "    return NotImplemented\n",
    "\n",
    "print(\"Data description after types are assigned:\")\n",
    "guess_types(world_data)\n",
    "world_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd259153-5114-49c5-bb2d-0d22a77e9d9e",
   "metadata": {},
   "source": [
    "Now we can see more complete statistics for our numerical columns.\n",
    "Our data is so much cleaner than when we started,\n",
    "but it still has some issues lurking in it and is not ready for our machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be0c96c-bb00-449b-8622-0cbd2b6569d5",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning and Smoothing\n",
    "\n",
    "Now that our data is cleaner, we can look closer at our numbers.\n",
    "It is always important to take time to go over your data.\n",
    "To help understand our data, we will use both aggregate statistics and manual inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99cd016-4404-4e28-80cf-50d89a4c9466",
   "metadata": {},
   "source": [
    "### Data Outliers\n",
    "\n",
    "Now, you may notice some inconsistencies (depending on how well you did in previous parts)\n",
    "in your data statistics (`describe()`).\n",
    "For example, you may notice a value for a percentage column above 1.0 or a population in the single digits.\n",
    "Looking at these aggregate statistics can help us recognize that there are issues in our data.\n",
    "However, we still need to isolate the specific entries with issues and fix them.\n",
    "\n",
    "To start, we want to look for [outliers](https://en.wikipedia.org/wiki/Outlier) in our data.\n",
    "An outlier is just a point that lies \"outside\" the expected range for our data.\n",
    "The exact definition for what is considered \"outside\" our expected range depends on the dataset and situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9383b68-2b4f-4b36-88cd-edc253e99b3f",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 2.A</h3>\n",
    "\n",
    "Complete the function below which takes in a frame, a number of standard deviations, and the name of a label column.\n",
    "This function will search all numeric columns for outliers.\n",
    "An outlier will be any value that is more that the specified number of standard deviations away from the column's mean.\n",
    "Any NaNs should be ignored.\n",
    "\n",
    "The return value should be a dict where the keys are the names of columns that contain an outlier\n",
    "and the value is a list of tuples with the value of the label column for that row and the outlier value.\n",
    "Columns without outliers (and non-numeric columns) should be omitted from the returned result.\n",
    "\n",
    "For example, a valid return from `find_outliers(world_data, 4.0, 'Country')` could be:\n",
    "```\n",
    "{\n",
    "    'Population': [\n",
    "        ('China', 1410539758.0),\n",
    "        ('India', 1389637446.0)\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Use this function as a chance to catch bugs you may have in your number parsing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9cf0cf-b733-4cf5-99e7-2e024d76fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(frame, deviations, label_column_name):\n",
    "    return NotImplemented\n",
    "\n",
    "print(\"Outliers found in our data:\")\n",
    "find_outliers(world_data, 4.0, 'Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907dd15d-07db-4fd0-9143-fa5fd4c4ea51",
   "metadata": {},
   "source": [
    "Once we have found outliers in our data, we have the hard decision of what to do with the outliers:\n",
    " - Are the outliers errors in the original data that we should discuss with the original data authors?\n",
    " - Are they a symptom of incorrect data parsing earlier in our pipeline?\n",
    " - Should they be replaced with a more typical value?\n",
    " - Should they be removed entirely?\n",
    " - Are they real and should just be kept in the data without modification.\n",
    "\n",
    "In our case, we will keep our outliers intact.\n",
    "However, use this as an opportunity to look for bugs in you number parsing code from Part 1.\n",
    "Incorrectly parsed numbers can easily show up as outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03112d61-4a2d-467b-b16c-d69bb880a696",
   "metadata": {},
   "source": [
    "### Data Imputation\n",
    "\n",
    "Besides outliers, another form of anomalous data we may see are *missing values*.\n",
    "Missing values may be represented in many different ways depending on the dataset:\n",
    "numpy.nan, -1, null, None, \"MISSING\", etc.\n",
    "\n",
    "Sometimes what to do with missing data is obvious given the dataset.\n",
    "For example, if a new country was founded in 2022 then the value in its \"Unemployment rate 2019\" should be missing.\n",
    "Neither a 0.0 nor 1.0 would make sense, the value just does not exist.\n",
    "\n",
    "However in more complex situations, deciding what to do with missing data can be very difficult.\n",
    "One potential way to deal with missing data is through [data imputation](https://en.wikipedia.org/wiki/Imputation_(statistics)).\n",
    "\"Imputing\" data is when we replace missing values with some derived value.\n",
    "We are essentially \"filling in the gaps\" in our data with values that make sense.\n",
    "There are many methods of choosing which values to impute, some of which are:\n",
    " - Using the **mean** value of the column (using non-empty values).\n",
    " - Using other values to create a machine learning model (often a regressor) to **predict** what the value should be.\n",
    " - Making a **random** guess (which can sometimes work better than you may expect).\n",
    " - Using knowledge of the domain to build a probabilistic model and then using that model to make a **educated random** guess.\n",
    "\n",
    "There is no fixed rule or theorem that will tell you what the best data imputation method is for each dataset or column.\n",
    "It will usually come down to the expertise of a data scientists (that's you!)\n",
    "to bridge the gap between the domain data and statistics and figure our the best way to impute missing data (or whether to leave it be).\n",
    "Always be careful when imputing values,\n",
    "since it may bias your data.\n",
    "\n",
    "In our data, the most sparsely populated columns (and candidates for imputation)\n",
    "are \"Literacy\" and the three \"Unemployment\" columns.\n",
    "\n",
    "The \"Literacy\" column could be a very interesting column to impute,\n",
    "because there are many [studies on different predictors of literacy in adults](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0243763).\n",
    "We may be able to use the other columns in our dataset (like \"Electricity access\", \"Internet access\", \"Improved Sanitation\", \"Improved Water\")\n",
    "to predict literacy rate.\n",
    "Unfortunately, building regressors is outside the scope of this assignment.\n",
    "\n",
    "Still, the \"Unemployment\" columns also provides an interesting data imputation opportunity for us.\n",
    "There are three columns that represent employment for three years (\"Unemployment rate 2021\", \"Unemployment rate 2020\", \"Unemployment rate 2019\"),\n",
    "and each country may have values for any number of those columns.\n",
    "To smooth out the data and impute missing values,\n",
    "we can combine these columns into one (\"Recent Unemployment\") and take the **mean** of all present values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d47814-b49d-4d34-b28b-49e2e88ed68a",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 2.B</h3>\n",
    "\n",
    "Complete the function below that takes a frame, a list of column names, and a new column name.\n",
    "Modify the frame to merge the provided columns into a single column with the provided name.\n",
    "To merge columns, take the mean of any present values.\n",
    "If no values are present, use `numpy.nan`.\n",
    "Return the passed-in frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b76b7c-9586-4bd8-a6a2-8c0c0884e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_columns(frame, merge_column_names, new_column_name):\n",
    "    return NotImplemented\n",
    "\n",
    "print(\"Data with merged unemployment data:\")\n",
    "columns = ['Unemployment rate 2019', 'Unemployment rate 2020', 'Unemployment rate 2021']\n",
    "merge_columns(world_data, columns, 'Recent Unemployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd55591-5c38-434c-81ee-d6268791ceb2",
   "metadata": {},
   "source": [
    "## Part 3: Encoding Data\n",
    "\n",
    "Let's finally deal with that pesky \"Export commodities\" column!\n",
    "It's not a number, but represents a list of items.\n",
    "It is common to deal with data that is not numeric (arbitrary strings, strings representing single items, strings representing list/sets of items, etc).\n",
    "To deal with these non-numeric columns, we need to encode them.\n",
    "That is, we need to convert them from a non-numeric form to a numeric one.\n",
    "\n",
    "In computer science, there are many encodings and encoding methods.\n",
    "An encoding that you are probably already familiar with is [ASCII](https://en.wikipedia.org/wiki/ASCII),\n",
    "which is a way to represent Latin letters as numbers.\n",
    "Encodings are just agreed upon ways to represent non-numeric values as numbers.\n",
    "\n",
    "In machine learning and data science, probably the most popular encoding method is [the One-Hot encoding](https://en.wikipedia.org/wiki/One-hot).\n",
    "In One-Hot encoding, we take all the possible values an item can take and assign each possible value an index.\n",
    "Presence of that value results in a 1, which absence results in a 0.\n",
    "Essentially, we are turning a list of items into a series of binary columns which ask \"Do you have this value?\".\n",
    "\n",
    "For example, consider the following tables.\n",
    "In the first one, a student's major is kept as a string (or a list of strings).\n",
    "To encode it, a column is created for each possible major and a 1 is present if that student has that major\n",
    "(otherwise a 0 is used).\n",
    "\n",
    "<center><img src=\"one-hot.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31908ac-0c6c-4734-9064-e6d797f0b176",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 3.A</h3>\n",
    "\n",
    "Complete the function below that takes in a frame and a column name.\n",
    "The function should modify the frame to add multiple columns represented a one-hot encoding of the specified column.\n",
    "Assume that the given column contains a comma-separated list of values.\n",
    "Each value should be made lowercase and have additional whitespace removed from the beginning and end.\n",
    "The new column names should be named: \"`<old column name>: <value>`.\n",
    "(Like in the students example above.)\n",
    "Return **a new frame** with the columns of the passed-in frame (minus the specified column) and all the new one-hot columns.\n",
    "\n",
    "Note that the above semantics will not work perfectly for our world data,\n",
    "but it will provide a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1936f-03c0-4aa2-be97-e219b8d60d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(frame, column_name):\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ccaa9-abe6-4889-96ec-3b06e36243ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before calling your function, we are going to clean up the data a little bit.\n",
    "# You are not required to learn what we are doing below (regular expressions),\n",
    "# but they are very useful and will always be useful to you.\n",
    "world_data['Export commodities'].replace(r'\\s*\\(\\d{4}(?:\\s*est\\.)?\\)\\s*', '',\n",
    "                                         regex = True, inplace = True)\n",
    "world_data['Export commodities'].replace(r'\\s*\\(\\d{2}%\\)\\s*', '',\n",
    "                                         regex = True, inplace = True)\n",
    "world_data['Export commodities'].replace(r'\\s*\\d{2}%\\s*', '',\n",
    "                                         regex = True, inplace = True)\n",
    "\n",
    "print(\"One-Hot encoded exports:\")\n",
    "world_data = one_hot(world_data, 'Export commodities')\n",
    "world_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35775e8-1be1-4b64-8f3a-c8937538a637",
   "metadata": {},
   "source": [
    "## Part 4: Joining Data\n",
    "\n",
    "Data is not always from a single frame/table or source.\n",
    "You will often need to merge and cross-reference data from other sources and in different frames.\n",
    "When we talk about merging data from multiple frames or tables,\n",
    "we usually use terminology that comes from databases and relational algebra.\n",
    "So we say \"table\" to refer to the abstract concept of tabular data (data with rows and columns) like a Pandas.DataFrame.\n",
    "Then, a [join](https://en.wikipedia.org/wiki/Join_(SQL)) is an operation that combines data from the columns of two different tables.\n",
    "(Note that the same table can actually be used multiple times (called a \"self-join\"),\n",
    "and joins can be chained together to include as many tables as desired.)\n",
    "\n",
    "In this section, we will briefly show the main different types of joins.\n",
    "The image below shows a graphical representation of the primary join types.\n",
    "When discussing joins, we will refer to the table on the left side of the join operator as the LHS (left-hand side)\n",
    "and the table on the right side of the join operator as the RHS (right-hand side).\n",
    "In the diagram below, $ A $ is always the LHS and $ B $ is always the RHS.\n",
    "\n",
    "Joins will typically specify some condition that must be meant for two rows to be merged,\n",
    "referred to as a \"join condition\".\n",
    "The most common join condition is equality for a set of columns.\n",
    "When a collection of columns are checked for equality in a join,\n",
    "we say we join \"on\" those columns.\n",
    "For example, we may say that we join $ A $ and $ B $ on the \"ID\" column.\n",
    "\n",
    "<center><img src=\"joins.png\"/></center>\n",
    "\n",
    "### Cross Join / Cartesian Product / Cross Product\n",
    "\n",
    "Cross joins (also known an \"Cartesian products\" or \"cross products\")\n",
    "are when every row in the LHS is paired with every row in the RHS.\n",
    "Therefore, the resulting table will have $ |A| * |B| $ number of rows.\n",
    "\n",
    "Cross joins can be though of as the basis for all other joins,\n",
    "since all possible rows are enumerated.\n",
    "\n",
    "### Inner Join\n",
    "\n",
    "Inner joins take only the rows from the LHS and RHS where the join conditions are met.\n",
    "We call an inner join where all shared columns (columns with the same name) between the LHS and RHS are checked for equality a *natural join*.\n",
    "\n",
    "### Full Outer Join\n",
    "\n",
    "Full outer joins (also known as \"outer joins\") ensure that every row from each table is represented.\n",
    "First, rows where the join condition are met are included.\n",
    "Then, rows from each table are included where the join condition are not met are included.\n",
    "For these non-matching rows, any columns that come from the other table are filled in with null or empty values\n",
    "(depending on the engine that performs the join).\n",
    "\n",
    "### Left Outer Join\n",
    "\n",
    "Left outer joins are like full outer joins,\n",
    "except only the non-matching rows from the LHS are included.\n",
    "\n",
    "### Right Outer Join\n",
    "\n",
    "Left outer joins are like full outer joins,\n",
    "except only the non-matching rows from the RHS are included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39929c57-4a58-4e81-9a28-62c229619e54",
   "metadata": {},
   "source": [
    "Now that you are an expert in join types, let's get some new data to join!\n",
    "To augment our data, we can get more information from the [World Health Organization](https://www.who.int/) (WHO).\n",
    "To tie in with our previous HO, we can get some 2022 statistics for each country on their Covid-19 status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f527b-392c-444a-9252-d24480119c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('who_covid_data_2022.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "who_data = pandas.DataFrame.from_dict(data, orient = 'index')\n",
    "who_data.sort_index(axis = 0, inplace = True)\n",
    "who_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224e793e-25a2-4439-ad58-9c7a43c36fb4",
   "metadata": {},
   "source": [
    "To perform joins in Pandas, a useful method is [DataFrame.join()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html).\n",
    "Of course, Pandas always has multiple ways to do anything, but the `DataFrame.join()` method is a good start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de966b0-5b9d-4cc9-b083-b633d0a48c90",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 4.A</h3>\n",
    "\n",
    "Complete the function below that takes in two frames and a list of column names.\n",
    "This function should return a new frame that contains the left outer join between these frames on the specified columns from the LHS.\n",
    "\n",
    "*Hint: Make sure to read the documentation on DataFrame.join() if you are going to use it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b38824-c796-44f3-bb29-0a78e361ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_join(lhs_frame, rhs_frame, column_names):\n",
    "    return NotImplemented\n",
    "\n",
    "print(\"World data that includes Covid-19 stats:\")\n",
    "covid_world_data = left_join(world_data, who_data, ['Country'])\n",
    "covid_world_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc4bd4-0e6e-427b-a330-7f8d1091468d",
   "metadata": {},
   "source": [
    "Now we can see our country data along with Covid-19 data for each country!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d5d9e-8bc5-409c-97d7-dfb0a5eee915",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_world_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ebc72-fa0e-4895-b280-5b255e02bdc3",
   "metadata": {},
   "source": [
    "Note that we will likely have rows from our world data that did not match up with the WHO data.\n",
    "To see these, we can just look for empty values in WHO columns (since a left join would put empty values there)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ab95b-9319-4b75-abe0-d5675da0609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_world_data[covid_world_data['Total_Vaccinations'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7830c3b3-7476-4e8f-baac-017c0ca53c7d",
   "metadata": {},
   "source": [
    "Looking at these results, we can understand why the WHO may not have data on some of them.\n",
    "Some are not technically countries (like \"Antarctica\"),\n",
    "some have ambiguous national status (like \"Taiwan\"),\n",
    "and some are just using different but valid names (like \"United States\" vs \"United States of America\").\n",
    "\n",
    "As a data scientist, think about ways that you could more efficiently join together these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fe205-d4b0-4fb9-a389-1226e47bce1a",
   "metadata": {},
   "source": [
    "Congratulations!\n",
    "You now have a grasp on the basics of data cleaning and munging (the soul of a data scientist)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
